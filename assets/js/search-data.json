{
  
    
        "post0": {
            "title": "Title",
            "content": "&gt; &quot;Produce Latent Factors, select the higher weights and use the ordinality to create multi-categories assignments to Movie Reviews. Finally re-classify the reviews per film and identify dominance.&quot; - toc:true - branch: master - badges: true - comments: true - author: Conwyn - categories: [fastai,language,ordinality] . %matplotlib inline %reload_ext autoreload !pip install -Uqq fastbook import fastbook fastbook.setup_book() from fastai import * !pip install git+https://github.com/alberanid/imdbpy . |████████████████████████████████| 727kB 4.3MB/s |████████████████████████████████| 51kB 7.4MB/s |████████████████████████████████| 204kB 40.0MB/s |████████████████████████████████| 1.2MB 38.2MB/s |████████████████████████████████| 51kB 7.9MB/s |████████████████████████████████| 61kB 8.3MB/s Mounted at /content/gdrive Collecting git+https://github.com/alberanid/imdbpy Cloning https://github.com/alberanid/imdbpy to /tmp/pip-req-build-hmq9dz76 Running command git clone -q https://github.com/alberanid/imdbpy /tmp/pip-req-build-hmq9dz76 Requirement already satisfied: SQLAlchemy in /usr/local/lib/python3.7/dist-packages (from IMDbPY==2021.5.12) (1.4.15) Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from IMDbPY==2021.5.12) (4.2.6) Requirement already satisfied: importlib-metadata; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy-&gt;IMDbPY==2021.5.12) (4.0.1) Requirement already satisfied: greenlet!=0.4.17; python_version &gt;= &#34;3&#34; in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy-&gt;IMDbPY==2021.5.12) (1.1.0) Requirement already satisfied: typing-extensions&gt;=3.6.4; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;SQLAlchemy-&gt;IMDbPY==2021.5.12) (3.7.4.3) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;SQLAlchemy-&gt;IMDbPY==2021.5.12) (3.4.1) Building wheels for collected packages: IMDbPY Building wheel for IMDbPY (setup.py) ... done Created wheel for IMDbPY: filename=IMDbPY-2021.5.12-cp37-none-any.whl size=299286 sha256=d58b37342e012a2b2db7958a97fe1fb458967157d5017d9fad86eef58458ebc9 Stored in directory: /tmp/pip-ephem-wheel-cache-63933vf_/wheels/0f/09/61/190df5e0276765680540f1562f2abca80e725a7e48595e993f Successfully built IMDbPY Installing collected packages: IMDbPY Successfully installed IMDbPY-2021.5.12 . Define the number of higher weights to investigate (FACTORS) and the number of heaviest films (Twenty). . from fastai.collab import * from fastai.tabular.all import * FACTORS=5 #Take the 10 latent factors Twenty = 100 #Only analyse 100 films # We need to bring in a prepared WiKi IMDB language model encoder and its vocab. import pickle import collections from imdb import IMDb . COLAB has no data retained between sessions so data is stored on your Google drive. The encoder is expected to be found in a folder called models . !mkdir /content/models . !cp /content/gdrive/MyDrive/finetunedE.pth /content/models . !cp /content/gdrive/MyDrive/savelm.p /content dls_lm = pickle.load( open( &quot;/content/savelm.p&quot;, &quot;rb&quot; ) ) . From the book. Get Movie Lens and identify 50 Latent Factors . path = untar_data(URLs.ML_100k) path.ls() ratings = pd.read_csv(path/&#39;u.data&#39;,delimiter=&#39; t&#39;,header=None,names=[&#39;user&#39;,&#39;movie&#39;,&#39;rating&#39;,&#39;timestamp&#39;]) ratings.head() movies = pd.read_csv(path/&#39;u.item&#39;,delimiter=&#39;|&#39;,encoding=&#39;latin-1&#39;,usecols=(0,1),names=(&#39;movie&#39;,&#39;title&#39;),header=None) movies.head() ratings=ratings.merge(movies) ratings.head() dls = CollabDataLoaders.from_df(ratings,item_name=&#39;title&#39;,bs=64) dls.show_batch() . user title rating . 0 542 | My Left Foot (1989) | 4 | . 1 422 | Event Horizon (1997) | 3 | . 2 311 | African Queen, The (1951) | 4 | . 3 595 | Face/Off (1997) | 4 | . 4 617 | Evil Dead II (1987) | 1 | . 5 158 | Jurassic Park (1993) | 5 | . 6 836 | Chasing Amy (1997) | 3 | . 7 474 | Emma (1996) | 3 | . 8 466 | Jackie Chan&#39;s First Strike (1996) | 3 | . 9 554 | Scream (1996) | 3 | . learn = collab_learner(dls, n_factors=50, y_range = (0,5.5)) learn.fit_one_cycle(5,5e-3,wd=0.1) . epoch train_loss valid_loss time . 0 | 0.959085 | 0.955102 | 00:07 | . 1 | 0.869222 | 0.876647 | 00:07 | . 2 | 0.745436 | 0.841352 | 00:07 | . 3 | 0.596926 | 0.825848 | 00:07 | . 4 | 0.482670 | 0.826195 | 00:07 | . Now look at the latent weights for each movie and pick the highest (FACTORS) weights and then using the movie title find the IMDB reviews later . movie_weight = learn.model.i_weight.weight idxs = movie_weight.argsort(descending=True) idxs5 = idxs[:,0:FACTORS] # Originally 5 movie_weight5 = [movie_weight[i,idxs5[i]] for i in range(movie_weight.shape[0])] idxm5s = movie_weight[:,0].argsort(descending=True) movie_weight5top = [] for i in range(FACTORS): #idxm5s: movie_weight5top.append(movie_weight5[idxm5s[i]]) movie_weight5toptitles = [] for i in range(FACTORS): #idxm5s: T0 = idxm5s[i].item() T1 = movies.iloc[T0].title movie_weight5toptitles.append(T1) newidxs=idxs #now give the review the attribute;idxs contains the latency number we just need to idxm5scpu to pull the high line and generate Lx Ly Lz assoiated with text idxs5[0:FACTORS,0:FACTORS] . idxs5list=[] for iii in range(idxs5.shape[0]): for jjj in range(idxs5.shape[1]): idxs5list.append(idxs5[iii][jjj].item()) counter=collections.Counter(idxs5list) print(counter.most_common(20)) . [(3, 318), (15, 298), (12, 272), (42, 258), (37, 254), (13, 252), (31, 247), (22, 244), (10, 231), (4, 224), (41, 218), (2, 212), (0, 211), (29, 209), (27, 209), (39, 203), (7, 196), (34, 184), (35, 182), (16, 182)] . Latency=idxs[idxm5s[:],0:FACTORS] . I notice that Latent Factor zero was dominating the analysis so here I remove it. . def tensorvaluezero(x): sum = False for i in x: e = i.item() if (e == 0.0): sum=True return sum TCList = [] for i,v in enumerate(Latency): if (tensorvaluezero(v.cpu()) == False ) : TCList.append(i) . len(TCList),len(Latency) . -211 . Just an idea but try find films with similar root mean square of ordinality. . # def tensorvalue(x): # sum = 0. # for i in x: # e = i.item() # sum =+ (e*e) # return math.sqrt(sum) # TCList = [] # TC = tensorvalue(tensor([3,15,12,42,37])) # for i,v in enumerate(Latency): # if (tensorvalue(v.cpu()) == TC ) : # TCList.append(i) # print(i) . 80 97 113 147 171 197 330 375 386 553 583 595 693 746 759 769 806 851 902 903 968 1001 1073 1210 1222 1239 1352 1377 1399 1414 1512 1538 1584 . Latency . tensor([[12, 0, 15, 19, 9], [ 0, 3, 35, 4, 28], [ 0, 2, 28, 31, 9], ..., [21, 15, 3, 33, 39], [10, 5, 41, 6, 21], [49, 36, 39, 33, 43]], device=&#39;cuda:0&#39;) . md=movies.iloc[idxm5s[:].cpu()].title . Choose the top &quot;Twenty&quot; movies with the highest weight for the first latent weight . top20movies = md.to_list()[0:Twenty] . print(TCList[0],movies.iloc[TCList[0]]) Twenty = len(TCList) top20movies = [md.to_list()[i] for i in TCList][0:20] . 23 movie 24 title Rumble in the Bronx (1995) Name: 23, dtype: object . top20movies[0] . &#39;Jade (1995)&#39; . Here we take the Latent Factors for the Movies and replicate to the Movie reviews from IMBD . LatencyString=[] for j in Latency[0:Twenty]: LT =&#39;&#39; temp_i = len(j) for k in j: MN = (k.item()) temp_i -= 1 if temp_i &gt; 0 : LT=LT+str(k.item())+&#39;;&#39; else: LT=LT+str(k.item()) LatencyString.append(LT) . LatencyString[0:10] . [&#39;12;0;15;19;9&#39;, &#39;0;3;35;4;28&#39;, &#39;0;2;28;31;9&#39;, &#39;0;8;28;13;45&#39;, &#39;0;3;46;35;8&#39;, &#39;0;3;15;39;36&#39;, &#39;35;0;7;8;10&#39;, &#39;31;15;0;40;13&#39;, &#39;0;15;29;12;20&#39;, &#39;0;9;8;45;14&#39;] . pdload=[] reviewCount = [] for i in range(len(top20movies)): ia = IMDb() imovies = ia.search_movie(str(top20movies[i])) if imovies != [] : mi = imovies[0].movieID imdbdata = ia.get_movie_reviews(str(mi))[&#39;data&#39;] # [&#39;reviews&#39;] if &#39;reviews&#39; in imdbdata: details = imdbdata[&#39;reviews&#39;] print(f&#39;*** {i} *** {len(details)} reviews&#39;) reviewCount.append((top20movies[i],len(details))) for j in details: #print(j[&#39;content&#39;]) #print(&#39;&#39;) pdload.append([top20movies[i],LatencyString[i],j[&#39;content&#39;]]) . *** 0 *** 24 reviews *** 1 *** 2 reviews *** 2 *** 11 reviews *** 3 *** 25 reviews *** 4 *** 19 reviews *** 5 *** 25 reviews *** 6 *** 25 reviews *** 8 *** 24 reviews *** 9 *** 24 reviews *** 10 *** 25 reviews *** 12 *** 25 reviews *** 13 *** 25 reviews *** 14 *** 25 reviews *** 15 *** 15 reviews *** 16 *** 21 reviews *** 17 *** 25 reviews *** 18 *** 25 reviews *** 19 *** 25 reviews . pdload[0] . [&#39;Jade (1995)&#39;, &#39;12;0;15;19;9&#39;, &#39;To say Friedkin &#39;s career has had its ups and downs is an understatement, his eighties filmography inarguably has enough bombs to sink a oil tanker. Yet eschewing their performances at the box office, many of his films yearn to be rediscovered, from &#34;Cruising&#34; to &#34;Deal of the Century&#34; to &#34;Rampage&#34;. Let &#39;s not kid ourselves, &#34;Jade&#34; is not a great film, and this is the fault of one man and one man alone - Joe Esterhas. If trash had a messiah, it would be him. For a fleeting moment in the nineties, Esterhas was paid by the bucketload to write formulaic movies for guys, and the erotic thriller has him to thank for its continuing lugubrious existence. &#34;Jade&#34; is interesting however, it is an erotic thriller without the erotic part. While Paul Verhoeven filled &#34;Basic Instinct&#34; chock full of the sleaze he had become renowned for, Friedkin &#39;s films are notable for primarily dealing with male characters, and are subsequently about as erotic as as a bowl of cereal. &#34;Jade&#34; is not about sex; it is about sexual jealousy. The talent of Linda Fiorentino cannot be underestimated here, giving depth to a part that amounts to no more than a typical male fantasy - part good girl, part whore - that &#39;s right, it &#39;s &#34;Crimes of Passion&#34; without Anthony Perkins and his bag of dildos. The leads are well cast and all give adequate performances, and Friedkin throws in all his usual directorial touches (subliminal images and, you guessed it, yet another bloody car chase). &#34;Jade&#34; is an enjoyable film, with delightfully silly twists and over-the-top violence (come on, you know you want to see Angie Everhart get run over again), and is given some class from it &#39;s cast and director, but, in the end, proves itself to be a guilty pleasure that makes one feel more guilt than pleasure.&#39;] . dfr=pd.DataFrame(pdload,columns=[&#39;Movie&#39;,&#39;Latency&#39;,&#39;Review&#39;]) . dfr.iloc[0] . Movie Jade (1995) Latency 12;0;15;19;9 Review To say Friedkin&#39;s career has had its ups and downs is an understatement, his eighties filmography inarguably has enough bombs to sink a oil tanker. Yet eschewing their performances at the box office, many of his films yearn to be rediscovered, from &#34;Cruising&#34; to &#34;Deal of the Century&#34; to &#34;Rampage&#34;. Let&#39;s not kid ourselves, &#34;Jade&#34; is not a great film, and this is the fault of one man and one man alone - Joe Esterhas. If trash had a messiah, it would be him. For a fleeting moment in the nineties, Esterhas was paid by the bucketload to write formulaic movies for guys, and the erotic thriller h... Name: 0, dtype: object . Now create the classifier but use vocab=dls_lm.vocab which we loaded from the Wiki IMDB dataloader . from fastai.text.all import * dlsr = TextDataLoaders.from_df(df=dfr, text_vocab=dls_lm.vocab,text_col=&#39;Review&#39;, label_col=&#39;Latency&#39;, label_delim=&quot;;&quot;,y_block=MultiCategoryBlock,splitter=RandomSplitter(0.2) ) dlsr.show_batch(max_n=3) dlsr.vocab[1] . /usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray return array(a, dtype, copy=False, order=order) . text None . 0 xxbos xxmaj the xxmaj great xxmaj famous as well as the xxmaj great xxmaj infamous occurrences in a nation &#39;s history are and always will be looked upon as subjects worthy of a film treatment . xxmaj whether an incident were to be filmed from a story and its screenplay form written directly for the screen or an adaptation of a xxmaj novel , a xxmaj short xxmaj story or a xxmaj stage xxmaj play , they are an important element of formulating our image of our xxmaj world . xxmaj right or wrong , it is a fact of life and one that we must learn to live xxunk good example of just what we are driving at is the occurrences of xxmaj october 26 , 1881 in xxmaj tombstone , xxmaj arizona . xxmaj known as &quot; the xxmaj gunfight at xxup o.k . xxmaj corral &quot; , | 0;16;27;34;9 | . 1 xxbos i often hear similar stories of people &#39;s first experiences watching xxmaj blade xxmaj runner , finding the film dull but coming to appreciate it years later - my story has the same trajectory . i first tried to watch xxmaj blade xxmaj runner ( of what i believe was xxmaj the xxmaj final xxmaj cut ) on xxup tv in xxmaj christmas 2009 , only to stop watching after half an hour due to boredom . xxmaj over the years , however , i would be compelled to return to xxmaj blade xxmaj runner several times and get more out of it with each viewing . xxmaj the tech - noir world of xxmaj blade xxmaj runner is one to get lost in with its use of neon and many billboards of geishas , albeit a more depressing , dystopian one than say that of xxmaj star xxmaj | 0;13;28;45;8 | . 2 xxbos xxmaj who could have possibly thought that xxmaj oliver xxmaj stone would surpass the level reached by &quot; jfk &quot; , one of the greatest political thrillers ever made ? xxmaj yet his &quot; nixon &quot; is not only the harrowing political biography of the most controversial and unpopular xxmaj president of the xxmaj united xxmaj states , but also the gripping psychological study of a tormented man who got too much to prove . xxmaj it &#39;s also a terrific movie served by an impressive casting : xxmaj anthony xxmaj hopkins , xxmaj joan xxmaj allen , xxmaj james xxmaj woods , xxmaj bob xxmaj hoskins , xxmaj ed xxmaj harris , xxup e.g. xxmaj marshall , xxmaj madeline xxmaj kahn and an unrecognizable xxmaj paul xxmaj sorvino as xxmaj henry xxmaj kissinger . xxmaj and it &#39;s definitely one of the best movies of 1995 , which | 0;28;36;4;9 | . [&#39;0&#39;, &#39;10&#39;, &#39;11&#39;, &#39;12&#39;, &#39;13&#39;, &#39;14&#39;, &#39;15&#39;, &#39;16&#39;, &#39;17&#39;, &#39;19&#39;, &#39;2&#39;, &#39;20&#39;, &#39;24&#39;, &#39;25&#39;, &#39;27&#39;, &#39;28&#39;, &#39;29&#39;, &#39;3&#39;, &#39;31&#39;, &#39;34&#39;, &#39;35&#39;, &#39;36&#39;, &#39;38&#39;, &#39;39&#39;, &#39;4&#39;, &#39;40&#39;, &#39;42&#39;, &#39;45&#39;, &#39;46&#39;, &#39;47&#39;, &#39;49&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;] . Using our Wiki/IMDB language model encoder let us build a classifier in order to predict the latent factors from the reviews. So we are building a classifier which is looking for the number of latent factors which were present in the top &quot;Twenty&quot; films. We are using the pre-trained Wiki-IMDB encoder and the IMDB vocab used in the pre-training. . learnr = text_classifier_learner(dlsr, AWD_LSTM, drop_mult=0.5, n_out=len(dlsr.vocab[1]), metrics=[]).to_fp16() . (len(dlsr.vocab[1]),len(counter),len(dls_lm.vocab),len(dlsr.vocab[0]),len(dlsr.vocab[1])) #dls_lm.vocab . (34, 50, 60008, 60008, 34) . learnr.load_encoder(&#39;finetunedE&#39;) . &lt;fastai.text.learner.TextLearner at 0x7f6340e8d210&gt; . . learnr.fit_one_cycle(1,2e-2) . epoch train_loss valid_loss time . 0 | 0.713931 | 0.663639 | 00:02 | . Following the box and slowly unfreezing . learn.freeze_to(-2) learnr.fit_one_cycle(1,slice(1e-2/(2.6**4),1e-2)) learn.freeze_to(-3) learnr.fit_one_cycle(1,slice(5e-3/(2.6**4),5e-3)) learnr.unfreeze() learnr.fit_one_cycle(2,slice(1e-3/(2.6**4),1e-3)) . epoch train_loss valid_loss time . 0 | 0.655238 | 0.648486 | 00:02 | . epoch train_loss valid_loss time . 0 | 0.632271 | 0.661978 | 00:02 | . epoch train_loss valid_loss time . 0 | 0.625277 | 0.677263 | 00:04 | . 1 | 0.619720 | 0.683465 | 00:04 | . dfr.iloc[0,2] . &#39;To say Friedkin &#39;s career has had its ups and downs is an understatement, his eighties filmography inarguably has enough bombs to sink a oil tanker. Yet eschewing their performances at the box office, many of his films yearn to be rediscovered, from &#34;Cruising&#34; to &#34;Deal of the Century&#34; to &#34;Rampage&#34;. Let &#39;s not kid ourselves, &#34;Jade&#34; is not a great film, and this is the fault of one man and one man alone - Joe Esterhas. If trash had a messiah, it would be him. For a fleeting moment in the nineties, Esterhas was paid by the bucketload to write formulaic movies for guys, and the erotic thriller has him to thank for its continuing lugubrious existence. &#34;Jade&#34; is interesting however, it is an erotic thriller without the erotic part. While Paul Verhoeven filled &#34;Basic Instinct&#34; chock full of the sleaze he had become renowned for, Friedkin &#39;s films are notable for primarily dealing with male characters, and are subsequently about as erotic as as a bowl of cereal. &#34;Jade&#34; is not about sex; it is about sexual jealousy. The talent of Linda Fiorentino cannot be underestimated here, giving depth to a part that amounts to no more than a typical male fantasy - part good girl, part whore - that &#39;s right, it &#39;s &#34;Crimes of Passion&#34; without Anthony Perkins and his bag of dildos. The leads are well cast and all give adequate performances, and Friedkin throws in all his usual directorial touches (subliminal images and, you guessed it, yet another bloody car chase). &#34;Jade&#34; is an enjoyable film, with delightfully silly twists and over-the-top violence (come on, you know you want to see Angie Everhart get run over again), and is given some class from it &#39;s cast and director, but, in the end, proves itself to be a guilty pleasure that makes one feel more guilt than pleasure.&#39; . learnr.predict(dfr.iloc[0,2]) . ((#13) [&#39;0&#39;,&#39;12&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;2&#39;,&#39;27&#39;,&#39;31&#39;...], tensor([ True, False, False, True, False, True, True, True, True, True, True, False, False, False, True, False, False, False, True, True, False, False, False, False, False, True, False, False, False, False, False, False, False, True]), tensor([0.5525, 0.4047, 0.4269, 0.6026, 0.4509, 0.5422, 0.6147, 0.5337, 0.6194, 0.5705, 0.5010, 0.4811, 0.4085, 0.4697, 0.5276, 0.4015, 0.4815, 0.4198, 0.5133, 0.5024, 0.4524, 0.4466, 0.4367, 0.4472, 0.4352, 0.5325, 0.4537, 0.4863, 0.4394, 0.4571, 0.4811, 0.3731, 0.3053, 0.5401])) . Now predict the latent factors for each movie based on their reviews . superpredictions=[] accRC=0 for m in range(len(reviewCount)): RC = reviewCount[m][1] Film = reviewCount[m][0] predictions=[] print(f&#39;film {Film} reviews {RC}&#39;) for l in range(reviewCount[m][1]+0): predictions.append(learnr.predict(dfr.iloc[accRC+l,2])[0]) accRC=accRC+RC superpredictions.append((Film,predictions)) . film Jade (1995) reviews 24 . film Paris Was a Woman (1995) reviews 2 . film Princess Bride, The (1987) reviews 11 . film Blade Runner (1982) reviews 25 . film Letter From Death Row, A (1998) reviews 19 . film Ice Storm, The (1997) reviews 25 . film Paradise Lost: The Child Murders at Robin Hood Hills (1996) reviews 25 . film Ulee&#39;s Gold (1997) reviews 24 . film C&#39;est arrivé près de chez vous (1992) reviews 24 . film Pretty Woman (1990) reviews 25 . film Nixon (1995) reviews 25 . film Browning Version, The (1994) reviews 25 . film Young Frankenstein (1974) reviews 25 . film Naked in New York (1994) reviews 15 . film Bewegte Mann, Der (1994) reviews 21 . film If Lucy Fell (1996) reviews 25 . film Some Like It Hot (1959) reviews 25 . film Twilight (1998) reviews 25 . (superpredictions[0][0],superpredictions[0][1]) . (&#39;Jade (1995)&#39;, [(#13) [&#39;0&#39;,&#39;12&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;2&#39;,&#39;27&#39;,&#39;31&#39;...], (#11) [&#39;0&#39;,&#39;12&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;20&#39;,&#39;27&#39;,&#39;29&#39;,&#39;34&#39;...], (#21) [&#39;0&#39;,&#39;12&#39;,&#39;13&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;2&#39;,&#39;25&#39;...], (#15) [&#39;0&#39;,&#39;11&#39;,&#39;12&#39;,&#39;13&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;20&#39;,&#39;27&#39;...], (#13) [&#39;0&#39;,&#39;12&#39;,&#39;13&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;27&#39;,&#39;29&#39;,&#39;34&#39;...], (#12) [&#39;0&#39;,&#39;12&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;20&#39;,&#39;27&#39;,&#39;38&#39;,&#39;40&#39;...], (#16) [&#39;0&#39;,&#39;12&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;2&#39;,&#39;20&#39;,&#39;25&#39;...], (#12) [&#39;0&#39;,&#39;12&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;2&#39;,&#39;27&#39;,&#39;31&#39;,&#39;34&#39;...], (#13) [&#39;0&#39;,&#39;12&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;20&#39;,&#39;25&#39;,&#39;27&#39;,&#39;29&#39;,&#39;34&#39;...], (#11) [&#39;0&#39;,&#39;12&#39;,&#39;15&#39;,&#39;17&#39;,&#39;19&#39;,&#39;20&#39;,&#39;25&#39;,&#39;29&#39;,&#39;34&#39;,&#39;40&#39;...], (#9) [&#39;0&#39;,&#39;12&#39;,&#39;14&#39;,&#39;15&#39;,&#39;17&#39;,&#39;19&#39;,&#39;27&#39;,&#39;31&#39;,&#39;34&#39;], (#21) [&#39;0&#39;,&#39;12&#39;,&#39;13&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;2&#39;,&#39;20&#39;,&#39;25&#39;...], (#20) [&#39;0&#39;,&#39;11&#39;,&#39;12&#39;,&#39;13&#39;,&#39;16&#39;,&#39;17&#39;,&#39;2&#39;,&#39;24&#39;,&#39;27&#39;,&#39;28&#39;...], (#10) [&#39;0&#39;,&#39;12&#39;,&#39;13&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;27&#39;,&#39;29&#39;,&#39;34&#39;], (#13) [&#39;12&#39;,&#39;13&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;20&#39;,&#39;24&#39;,&#39;27&#39;,&#39;29&#39;...], (#11) [&#39;0&#39;,&#39;12&#39;,&#39;15&#39;,&#39;17&#39;,&#39;19&#39;,&#39;20&#39;,&#39;29&#39;,&#39;34&#39;,&#39;40&#39;,&#39;49&#39;...], (#7) [&#39;0&#39;,&#39;12&#39;,&#39;15&#39;,&#39;19&#39;,&#39;25&#39;,&#39;34&#39;,&#39;40&#39;], (#16) [&#39;0&#39;,&#39;12&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;2&#39;,&#39;20&#39;,&#39;27&#39;...], (#21) [&#39;0&#39;,&#39;12&#39;,&#39;13&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;2&#39;,&#39;20&#39;,&#39;25&#39;,&#39;28&#39;...], (#11) [&#39;0&#39;,&#39;12&#39;,&#39;15&#39;,&#39;19&#39;,&#39;20&#39;,&#39;25&#39;,&#39;29&#39;,&#39;31&#39;,&#39;34&#39;,&#39;40&#39;...], (#24) [&#39;0&#39;,&#39;11&#39;,&#39;13&#39;,&#39;14&#39;,&#39;16&#39;,&#39;17&#39;,&#39;2&#39;,&#39;20&#39;,&#39;24&#39;,&#39;25&#39;...], (#12) [&#39;0&#39;,&#39;12&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;20&#39;,&#39;27&#39;,&#39;29&#39;...], (#17) [&#39;0&#39;,&#39;12&#39;,&#39;13&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;20&#39;,&#39;24&#39;,&#39;27&#39;...], (#10) [&#39;0&#39;,&#39;12&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;19&#39;,&#39;27&#39;,&#39;34&#39;,&#39;9&#39;]]) . Now we are going to plot the predicted Latent Factors per movie . import math int(math.sqrt(len(superpredictions))) . 4 . superpredictions[4] . (&#39;Letter From Death Row, A (1998)&#39;, [(#22) [&#39;0&#39;,&#39;11&#39;,&#39;12&#39;,&#39;13&#39;,&#39;16&#39;,&#39;17&#39;,&#39;20&#39;,&#39;24&#39;,&#39;27&#39;,&#39;28&#39;...], (#20) [&#39;0&#39;,&#39;11&#39;,&#39;12&#39;,&#39;13&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;24&#39;,&#39;27&#39;...], (#17) [&#39;11&#39;,&#39;13&#39;,&#39;16&#39;,&#39;17&#39;,&#39;24&#39;,&#39;25&#39;,&#39;27&#39;,&#39;35&#39;,&#39;38&#39;,&#39;39&#39;...], (#15) [&#39;0&#39;,&#39;11&#39;,&#39;13&#39;,&#39;14&#39;,&#39;16&#39;,&#39;17&#39;,&#39;24&#39;,&#39;27&#39;,&#39;3&#39;,&#39;34&#39;...], (#19) [&#39;0&#39;,&#39;11&#39;,&#39;13&#39;,&#39;14&#39;,&#39;16&#39;,&#39;17&#39;,&#39;2&#39;,&#39;24&#39;,&#39;27&#39;,&#39;28&#39;...], (#20) [&#39;11&#39;,&#39;13&#39;,&#39;16&#39;,&#39;17&#39;,&#39;24&#39;,&#39;25&#39;,&#39;27&#39;,&#39;28&#39;,&#39;29&#39;,&#39;34&#39;...], (#21) [&#39;0&#39;,&#39;12&#39;,&#39;13&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;2&#39;,&#39;25&#39;,&#39;27&#39;...], (#18) [&#39;0&#39;,&#39;13&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;2&#39;,&#39;27&#39;,&#39;28&#39;,&#39;3&#39;...], (#21) [&#39;0&#39;,&#39;11&#39;,&#39;13&#39;,&#39;16&#39;,&#39;17&#39;,&#39;20&#39;,&#39;24&#39;,&#39;25&#39;,&#39;27&#39;,&#39;3&#39;...], (#20) [&#39;0&#39;,&#39;11&#39;,&#39;13&#39;,&#39;16&#39;,&#39;17&#39;,&#39;2&#39;,&#39;20&#39;,&#39;28&#39;,&#39;29&#39;,&#39;3&#39;...], (#19) [&#39;11&#39;,&#39;13&#39;,&#39;16&#39;,&#39;17&#39;,&#39;20&#39;,&#39;24&#39;,&#39;25&#39;,&#39;27&#39;,&#39;34&#39;,&#39;35&#39;...], (#19) [&#39;0&#39;,&#39;11&#39;,&#39;13&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;24&#39;,&#39;25&#39;,&#39;27&#39;,&#39;3&#39;...], (#18) [&#39;11&#39;,&#39;16&#39;,&#39;20&#39;,&#39;24&#39;,&#39;25&#39;,&#39;27&#39;,&#39;28&#39;,&#39;34&#39;,&#39;35&#39;,&#39;36&#39;...], (#22) [&#39;0&#39;,&#39;11&#39;,&#39;13&#39;,&#39;16&#39;,&#39;17&#39;,&#39;2&#39;,&#39;24&#39;,&#39;25&#39;,&#39;27&#39;,&#39;28&#39;...], (#22) [&#39;11&#39;,&#39;12&#39;,&#39;13&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;2&#39;,&#39;24&#39;,&#39;25&#39;,&#39;27&#39;...], (#20) [&#39;0&#39;,&#39;13&#39;,&#39;16&#39;,&#39;17&#39;,&#39;24&#39;,&#39;25&#39;,&#39;28&#39;,&#39;3&#39;,&#39;34&#39;,&#39;35&#39;...], (#18) [&#39;0&#39;,&#39;11&#39;,&#39;13&#39;,&#39;16&#39;,&#39;24&#39;,&#39;25&#39;,&#39;27&#39;,&#39;28&#39;,&#39;29&#39;,&#39;3&#39;...], (#19) [&#39;0&#39;,&#39;11&#39;,&#39;13&#39;,&#39;16&#39;,&#39;17&#39;,&#39;24&#39;,&#39;25&#39;,&#39;27&#39;,&#39;28&#39;,&#39;29&#39;...], (#14) [&#39;0&#39;,&#39;12&#39;,&#39;13&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;,&#39;27&#39;,&#39;29&#39;,&#39;3&#39;,&#39;31&#39;...]]) . reviewCount[0:10] . [(&#39;Jade (1995)&#39;, 24), (&#39;Paris Was a Woman (1995)&#39;, 2), (&#39;Princess Bride, The (1987)&#39;, 11), (&#39;Blade Runner (1982)&#39;, 25), (&#39;Letter From Death Row, A (1998)&#39;, 19), (&#39;Ice Storm, The (1997)&#39;, 25), (&#39;Paradise Lost: The Child Murders at Robin Hood Hills (1996)&#39;, 25), (&#34;Ulee&#39;s Gold (1997)&#34;, 24), (&#34;C&#39;est arrivé près de chez vous (1992)&#34;, 24), (&#39;Pretty Woman (1990)&#39;, 25)] . . From observation COLAB likes all the matplotlib in one cell . matplotlib.rcParams[&#39;figure.figsize&#39;] = [256, 64*1024/256-1] import math pict = int(math.sqrt(len(superpredictions)))+1 if pict &gt; 8 : pict = 8 pictw = pict picth = ((len(superpredictions))//pict) + 1 print(picth,pictw) _,axs = plt.subplots(picth,pictw) #axs.ravel() for boxcount,sp in enumerate(superpredictions): #print(sp[0]) reviewCountForTitle = reviewCount[boxcount][1] cord = (boxcount//(pictw),boxcount-(boxcount//pictw)*pictw) #cord = boxcount flat_list = [item for sublist in sp[1] for item in sublist] flat_list.sort() axs[cord].hist(flat_list, density=False, bins=len(dlsr.vocab[1])) # density=False would make counts axs[cord].set_title(str(sp[0]+&quot;:&quot;+str(reviewCountForTitle)),fontsize=108) # axs[cord].ylabel(&#39;Frequency&#39;) # axs[cord].xlabel(&#39;Data&#39;); plt.tight_layout() . 4 5 .",
            "url": "https://conwyn.github.io/MyBlogs/2021/05/21/_05_22_MLIMDB.html",
            "relUrl": "/2021/05/21/_05_22_MLIMDB.html",
            "date": " • May 21, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://conwyn.github.io/MyBlogs/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://conwyn.github.io/MyBlogs/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://conwyn.github.io/MyBlogs/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://conwyn.github.io/MyBlogs/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}